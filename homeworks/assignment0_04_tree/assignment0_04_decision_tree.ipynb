{"cells":[{"cell_type":"markdown","metadata":{"id":"M9OeG7CH3yTx"},"source":["## assignment 04: Decision Tree construction"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICc8ktTy3yT0","executionInfo":{"status":"ok","timestamp":1639937178725,"user_tz":-180,"elapsed":307,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}},"outputId":"622ceab9-0fbe-4e5a-b3cf-b444ab278c8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-12-19 18:06:17--  https://raw.githubusercontent.com/girafe-ai/ml-mipt/21f_made/homeworks/assignment0_04_tree/tree.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9501 (9.3K) [text/plain]\n","Saving to: ‘tree.py’\n","\n","\rtree.py               0%[                    ]       0  --.-KB/s               \rtree.py             100%[===================>]   9.28K  --.-KB/s    in 0s      \n","\n","2021-12-19 18:06:17 (61.8 MB/s) - ‘tree.py’ saved [9501/9501]\n","\n"]}],"source":["# If working in colab, uncomment the following line\n","! wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/21f_made/homeworks/assignment0_04_tree/tree.py -nc"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNupTiv03yT2","executionInfo":{"status":"ok","timestamp":1639937835926,"user_tz":-180,"elapsed":290,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}},"outputId":"46d05e8b-103c-4d6f-9e74-46b1113ca242"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","from sklearn.base import BaseEstimator\n","from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","import pandas as pd\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"LzhC_2l53yT2"},"source":["Let's fix the `random_state` (a.k.a. random seed)."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"8I1DGh5T3yT2","executionInfo":{"status":"ok","timestamp":1639937838308,"user_tz":-180,"elapsed":4,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"outputs":[],"source":["RANDOM_STATE = 42"]},{"cell_type":"markdown","metadata":{"id":"iWu6tg883yT3"},"source":["__Your ultimate task for today is to impement the `DecisionTree` class and use it to solve classification and regression problems.__\n","\n","__Specifications:__\n","- The class inherits from `sklearn.BaseEstimator`;\n","- Constructor is implemented for you. It has the following parameters:\n","    * `max_depth` - maximum depth of the tree; `np.inf` by default\n","    * `min_samples_split` - minimal number of samples in the leaf to make a split; `2` by default;\n","    * `criterion` - criterion to select the best split; in classification one of `['gini', 'entropy']`, default `gini`; in regression `variance`;\n","\n","- `fit` method takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and `y` (`numpy.array` of type float shaped `(n_objects, 1)` in regression; `numpy.array` of type int shaped `(n_objects, 1)` with class labels in classification). It works inplace and fits the `DecisionTree` class instance to the provided data from scratch.\n","\n","- `predict` method takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and returns the predicted $\\hat{y}$ values. In classification it is a class label for every object (the most frequent in the leaf; if several classes meet this requirement select the one with the smallest class index). In regression it is the desired constant (e.g. mean value for `variance` criterion)\n","\n","- `predict_proba` method (works only for classification (`gini` or `entropy` criterion). It takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and returns the `numpy.array` of type `float` shaped `(n_objects, n_features)` with class probabilities for every object from `X`. Class $i$ probability equals the ratio of $i$ class objects that got in this node in the training set.\n","\n","    \n","__Small recap:__\n","\n","To find the optimal split the following functional is evaluated:\n","    \n","$$G(j, t) = H(Q) - \\dfrac{|L|}{|Q|} H(L) - \\dfrac{|R|}{|Q|} H(R),$$\n","    where $Q$ is the dataset from the current node, $L$ and $R$ are left and right subsets defined by the split $x^{(j)} < t$.\n","\n","\n","\n","1. Classification. Let $p_i$ be the probability of $i$ class in subset $X$ (ratio of the $i$ class objects in the dataset). The criterions are defined as:\n","    \n","    * `gini`: Gini impurity $$H(R) = 1 -\\sum_{i = 1}^K p_i^2$$\n","    \n","    * `entropy`: Entropy $$H(R) = -\\sum_{i = 1}^K p_i \\log(p_i)$$ (One might use the natural logarithm).\n","    \n","2. Regression. Let $y_l$ be the target value for the $R$, $\\mathbf{y} = (y_1, \\dots, y_N)$ – all targets for the selected dataset $X$.\n","    \n","    * `variance`: $$H(R) = \\dfrac{1}{|R|} \\sum_{y_j \\in R}(y_j - \\text{mean}(\\mathbf{y}))^2$$\n","    \n","    * `mad_median`: $$H(R) = \\dfrac{1}{|R|} \\sum_{y_j \\in R}|y_j - \\text{median}(\\mathbf{y})|$$\n","        \n"]},{"cell_type":"markdown","metadata":{"id":"dN57pYIs3yT4"},"source":["**Hints and comments**:\n","\n","* No need to deal with categorical features, they will not be present.\n","* Siple greedy recursive procedure is enough. However, you can speed it up somehow (e.g. using percentiles).\n","* Please, do not copy implementations available online. You are supposed to build very simple example of the Decision Tree."]},{"cell_type":"markdown","metadata":{"id":"pH3bC0803yT4"},"source":["File `tree.py` is waiting for you. Implement all the needed methods in that file."]},{"cell_type":"markdown","metadata":{"id":"gvm0MGME3yT4"},"source":["### Check yourself"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"T6nqepBJ3yT4","executionInfo":{"status":"ok","timestamp":1639937841212,"user_tz":-180,"elapsed":2,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"outputs":[],"source":["from tree import entropy, gini, variance, mad_median, DecisionTree"]},{"cell_type":"markdown","metadata":{"id":"jVPQWzOm3yT5"},"source":["#### Simple check"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"uBuugqse3yT5","executionInfo":{"status":"ok","timestamp":1639937842620,"user_tz":-180,"elapsed":4,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"outputs":[],"source":["X = np.ones((4, 5), dtype=float) * np.arange(4)[:, None]\n","y = np.arange(4)[:, None] + np.asarray([0.2, -0.3, 0.1, 0.4])[:, None]\n","class_estimator = DecisionTree(max_depth=10, criterion_name='gini')\n","\n","(X_l, y_l), (X_r, y_r) = class_estimator.make_split(1, 1., X, y)\n","\n","assert np.array_equal(X[:1], X_l)\n","assert np.array_equal(X[1:], X_r)\n","assert np.array_equal(y[:1], y_l)\n","assert np.array_equal(y[1:], y_r)"]},{"cell_type":"markdown","metadata":{"id":"JH1gRoKK3yT5"},"source":["#### Classification problem"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"bEzwuDol3yT6","executionInfo":{"status":"ok","timestamp":1639937844042,"user_tz":-180,"elapsed":275,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"outputs":[],"source":["digits_data = load_digits().data\n","digits_target = load_digits().target[:, None] # to make the targets consistent with our model interfaces\n","X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_target, test_size=0.2, random_state=RANDOM_STATE)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"kJMCqWJI3yT6","executionInfo":{"status":"ok","timestamp":1639937845342,"user_tz":-180,"elapsed":2,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"outputs":[],"source":["assert len(y_train.shape) == 2 and y_train.shape[0] == len(X_train)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CrlwHpdn3yT6","executionInfo":{"status":"ok","timestamp":1639937881683,"user_tz":-180,"elapsed":7771,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}},"outputId":"b2845fd0-85ef-4dbf-dd5b-448eaab7961f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n","  ret, rcount, out=ret, casting='unsafe', subok=False)\n"]},{"output_type":"stream","name":"stdout","text":["0.8638888888888889\n"]}],"source":["class_estimator = DecisionTree(max_depth=10, criterion_name='gini')\n","class_estimator.fit(X_train, y_train)\n","ans = class_estimator.predict(X_test)\n","accuracy_gini = accuracy_score(y_test, ans)\n","print(accuracy_gini)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"uy16ArRl3yT6","executionInfo":{"status":"ok","timestamp":1639937886636,"user_tz":-180,"elapsed":249,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"outputs":[],"source":["reference = np.array([0.09027778, 0.09236111, 0.08333333, 0.09583333, 0.11944444,\n","       0.13888889, 0.09930556, 0.09444444, 0.08055556, 0.10555556])"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrNZgcEh3yT6","executionInfo":{"status":"ok","timestamp":1639938562030,"user_tz":-180,"elapsed":7050,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}},"outputId":"4676bab2-7c3a-47b2-b498-697609afa019"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n","  ret, rcount, out=ret, casting='unsafe', subok=False)\n"]},{"output_type":"stream","name":"stdout","text":["0.8861111111111111\n"]}],"source":["class_estimator = DecisionTree(max_depth=10, criterion_name='entropy')\n","class_estimator.fit(X_train, y_train)\n","ans = class_estimator.predict(X_test)\n","accuracy_entropy = accuracy_score(y_test, ans)\n","print(accuracy_entropy)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"JyYOqA3j3yT7","executionInfo":{"status":"error","timestamp":1639938562032,"user_tz":-180,"elapsed":13,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}},"outputId":"0061e247-6ad6-4e3d-f5bd-e168e18ef8ff"},"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-f669dd295d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m  \u001b[0;36m0.84\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maccuracy_gini\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m  \u001b[0;36m0.86\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maccuracy_entropy\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAssertionError\u001b[0m: "]}],"source":["assert  0.84 < accuracy_gini < 0.9\n","assert  0.86 < accuracy_entropy < 0.9\n","assert np.sum(np.abs(class_estimator.predict_proba(X_test).mean(axis=0) - reference)) < 1e-4"]},{"cell_type":"markdown","metadata":{"id":"LzJnoUGX3yT7"},"source":["Let's use 5-fold cross validation (`GridSearchCV`) to find optimal values for `max_depth` and `criterion` hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNyWhYRI3yT7"},"outputs":[],"source":["param_grid = {'max_depth': range(3,11), 'criterion_name': ['gini', 'entropy']}\n","gs = GridSearchCV(DecisionTree(), param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbXPhirU3yT7"},"outputs":[],"source":["%%time\n","gs.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96IOQDC_3yT7"},"outputs":[],"source":["gs.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynqD166v3yT8"},"outputs":[],"source":["assert gs.best_params_['criterion_name'] == 'entropy'\n","assert 6 < gs.best_params_['max_depth'] < 9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6q0uc5A3yT8"},"outputs":[],"source":["plt.figure(figsize=(10, 8))\n","plt.title(\"The dependence of quality on the depth of the tree\")\n","plt.plot(np.arange(3,11), gs.cv_results_['mean_test_score'][:8], label='Gini')\n","plt.plot(np.arange(3,11), gs.cv_results_['mean_test_score'][8:], label='Entropy')\n","plt.legend(fontsize=11, loc=1)\n","plt.xlabel(\"max_depth\")\n","plt.ylabel('accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"x_O0V_fh3yT8"},"source":["#### Regression problem"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HGcKCgS3yT8"},"outputs":[],"source":["regr_data = load_boston().data\n","regr_target = load_boston().target[:, None] # to make the targets consistent with our model interfaces\n","RX_train, RX_test, Ry_train, Ry_test = train_test_split(regr_data, regr_target, test_size=0.2, random_state=RANDOM_STATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AU5AipbR3yT8"},"outputs":[],"source":["regressor = DecisionTree(max_depth=10, criterion_name='mad_median')\n","regressor.fit(RX_train, Ry_train)\n","predictions_mad = regressor.predict(RX_test)\n","mse_mad = mean_squared_error(Ry_test, predictions_mad)\n","print(mse_mad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YR1nNcLt3yT8"},"outputs":[],"source":["regressor = DecisionTree(max_depth=10, criterion_name='variance')\n","regressor.fit(RX_train, Ry_train)\n","predictions_mad = regressor.predict(RX_test)\n","mse_var = mean_squared_error(Ry_test, predictions_mad)\n","print(mse_var)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IXLwhBNk3yT9"},"outputs":[],"source":["assert 9 < mse_mad < 20\n","assert 8 < mse_var < 12"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lugbdGl33yT9"},"outputs":[],"source":["param_grid_R = {'max_depth': range(2,9), 'criterion_name': ['variance', 'mad_median']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DiyyPZPo3yT9"},"outputs":[],"source":["gs_R = GridSearchCV(DecisionTree(), param_grid=param_grid_R, cv=5, scoring='neg_mean_squared_error', n_jobs=-2)\n","gs_R.fit(RX_train, Ry_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zZdlA4F3yT9"},"outputs":[],"source":["gs_R.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9F_JIysn3yT9"},"outputs":[],"source":["assert gs_R.best_params_['criterion_name'] == 'mad_median'\n","assert 3 < gs_R.best_params_['max_depth'] < 7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHfrGyVC3yT9"},"outputs":[],"source":["var_scores = gs_R.cv_results_['mean_test_score'][:7]\n","mad_scores = gs_R.cv_results_['mean_test_score'][7:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oYbJBneq3yT-"},"outputs":[],"source":["plt.figure(figsize=(10, 8))\n","plt.title(\"The dependence of neg_mse on the depth of the tree\")\n","plt.plot(np.arange(2,9), var_scores, label='variance')\n","plt.plot(np.arange(2,9), mad_scores, label='mad_median')\n","plt.legend(fontsize=11, loc=1)\n","plt.xlabel(\"max_depth\")\n","plt.ylabel('neg_mse')\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"assignment0_04_decision_tree.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}