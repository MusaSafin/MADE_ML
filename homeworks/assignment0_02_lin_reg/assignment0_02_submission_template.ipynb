{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"assignment0_02_submission_template.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"KfmTOlwXpVg-"},"source":["Before you submit this notebook, make sure everything runs as expected in the local test cases. \n","Please, paste the solution to the designed cell and do not change anything else.\n","\n","Also, please, leave your first and last names below"]},{"cell_type":"code","metadata":{"id":"mOdKUojppVhG","executionInfo":{"status":"ok","timestamp":1639590343733,"user_tz":-180,"elapsed":13,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"source":["FirstName = \"Musa\"\n","LastName = \"Safin\""],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8TUZ9BhpVhI"},"source":["---"]},{"cell_type":"code","metadata":{"id":"QcPkvEjOpVhJ","executionInfo":{"status":"ok","timestamp":1639590343737,"user_tz":-180,"elapsed":12,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"source":["import sys\n","\n","import numpy as np\n","import unittest\n","import time\n","\n","import collections\n","import pickle\n","import io"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"ef05da190517118a9c577e378fd64fc2","grade":false,"grade_id":"cell-ac8fc52d8a39ccb4","locked":false,"schema_version":3,"solution":true,"task":false},"id":"kdQSrjIUpVhJ","executionInfo":{"status":"ok","timestamp":1639590344046,"user_tz":-180,"elapsed":3,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"source":["import numpy as np\n","\n","\n","class LossAndDerivatives:\n","    @staticmethod\n","    def mse(X, Y, w):\n","        \"\"\"\n","        X : numpy array of shape (`n_observations`, `n_features`)\n","        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n","        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n","        Return : float\n","            single number with MSE value of linear model (X.dot(w)) with no bias term\n","            on the selected dataset.\n","        \n","        Comment: If Y is two-dimentional, average the error over both dimentions.\n","        \"\"\"\n","\n","        return np.mean((X.dot(w) - Y)**2)\n","\n","    @staticmethod\n","    def mae(X, Y, w):\n","        \"\"\"\n","        X : numpy array of shape (`n_observations`, `n_features`)\n","        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n","        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n","                \n","        Return: float\n","            single number with MAE value of linear model (X.dot(w)) with no bias term\n","            on the selected dataset.\n","        Comment: If Y is two-dimentional, average the error over both dimentions.\n","        \"\"\"\n","\n","        # YOUR CODE HERE    \n","        return np.mean(np.abs(X.dot(w) - Y))\n","\n","    @staticmethod\n","    def l2_reg(w):\n","        \"\"\"\n","        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n","        Return: float\n","            single number with sum of squared elements of the weight matrix ( \\sum_{ij} w_{ij}^2 )\n","        Computes the L2 regularization term for the weight matrix w.\n","        \"\"\"\n","        \n","        # YOUR CODE HERE\n","        return np.sum(w ** 2)\n","\n","    @staticmethod\n","    def l1_reg(w):\n","        \"\"\"\n","        w : numpy array of shape (`n_features`, `target_dimentionality`)\n","        Return : float\n","            single number with sum of the absolute values of the weight matrix ( \\sum_{ij} |w_{ij}| )\n","        \n","        Computes the L1 regularization term for the weight matrix w.\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        return np.sum(np.abs(w))\n","\n","    @staticmethod\n","    def no_reg(w):\n","        \"\"\"\n","        Simply ignores the regularization\n","        \"\"\"\n","        return 0.\n","    \n","    @staticmethod\n","    def mse_derivative(X, Y, w):\n","        \"\"\"\n","        X : numpy array of shape (`n_observations`, `n_features`)\n","        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n","        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n","        \n","        Return : numpy array of same shape as `w`\n","        Computes the MSE derivative for linear regression (X.dot(w)) with no bias term\n","        w.r.t. w weight matrix.\n","        \n","        Please mention, that in case `target_dimentionality` > 1 the error is averaged along this\n","        dimension as well, so you need to consider that fact in derivative implementation.\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        dif = X.dot(w) - Y\n","        return 2 * X.T.dot(dif) / (X.shape[0] * Y.shape[1])\n","\n","    @staticmethod\n","    def mae_derivative(X, Y, w):\n","        \"\"\"\n","        X : numpy array of shape (`n_observations`, `n_features`)\n","        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n","        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n","        \n","        Return : numpy array of same shape as `w`\n","        Computes the MAE derivative for linear regression (X.dot(w)) with no bias term\n","        w.r.t. w weight matrix.\n","        \n","        Please mention, that in case `target_dimentionality` > 1 the error is averaged along this\n","        dimension as well, so you need to consider that fact in derivative implementation.\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        dif = np.sign(X.dot(w) - Y)\n","        return X.T.dot(dif) / (X.shape[0] * Y.shape[1])\n","\n","    @staticmethod\n","    def l2_reg_derivative(w):\n","        \"\"\"\n","        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n","        Return : numpy array of same shape as `w`\n","        Computes the L2 regularization term derivative w.r.t. the weight matrix w.\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        return 2 * w\n","\n","    @staticmethod\n","    def l1_reg_derivative(w):\n","        \"\"\"\n","        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n","        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n","        Return : numpy array of same shape as `w`\n","        Computes the L1 regularization term derivative w.r.t. the weight matrix w.\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        return np.sign(w)\n","\n","    @staticmethod\n","    def no_reg_derivative(w):\n","        \"\"\"\n","        Simply ignores the derivative\n","        \"\"\"\n","        return np.zeros_like(w)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Pywf7uLpVhK"},"source":["### Test 0: Initialization (0.01 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"a98be3ff4b18d890434a80e95638bae1","grade":true,"grade_id":"cell-3473b7b6ffd64d07","locked":true,"points":0.01,"schema_version":3,"solution":false,"task":false},"id":"eTn6Be_3pVhL","executionInfo":{"status":"ok","timestamp":1639590344047,"user_tz":-180,"elapsed":3,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"source":["# do not change this cell\n","loss_and_derivatives = LossAndDerivatives"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mxnkbf_2pVhM"},"source":["### Test 1: MSE derivative (0.24 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"0647ec1f1217cd0161950529355d0484","grade":true,"grade_id":"cell-e3503c286039ec55","locked":true,"points":0.24,"schema_version":3,"solution":false,"task":false},"id":"9K8agA-epVhN","executionInfo":{"status":"ok","timestamp":1639590355121,"user_tz":-180,"elapsed":231,"user":{"displayName":"Муса Сафин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17185596362499426241"}}},"source":["mse_derivative = LossAndDerivatives.mse_derivative(X_ref, y_ref, w_hat)\n","assert np.allclose(mse_derivative, ref_dict['mse_derivative'], atol=1e-4)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TuGk1b7fpVhO"},"source":["### Test 2: MAE derivative (0.25 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"f05ee94b6387df0e7ed0336245082461","grade":true,"grade_id":"cell-e2c4124a6f815118","locked":true,"points":0.25,"schema_version":3,"solution":false,"task":false},"id":"Xf2kDKDWpVhO"},"source":["mae_derivative = LossAndDerivatives.mae_derivative(X_ref, y_ref, w_hat)\n","assert np.allclose(mae_derivative, ref_dict['mae_derivative'], atol=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RGIMWN12pVhO"},"source":["### Test 3: L1 reg derivative (0.15 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"8b101bf7c2bb674e5ad26dafe450781b","grade":true,"grade_id":"cell-69473387a23d8dff","locked":true,"points":0.15,"schema_version":3,"solution":false,"task":false},"id":"uHpjS6NmpVhP"},"source":["l2_reg_derivative = LossAndDerivatives.l2_reg_derivative(w_hat)\n","assert np.allclose(l2_reg_derivative, ref_dict['l2_reg_derivative'], atol=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HG5ZvAFSpVhP"},"source":["### Test 4: L1 reg derivative (0.15 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"205f29e8c5727c60ff129ce0bfe89ecf","grade":true,"grade_id":"cell-3460671ba79fd04a","locked":true,"points":0.15,"schema_version":3,"solution":false,"task":false},"id":"UU1iyUE7pVhP"},"source":["l1_reg_derivative = LossAndDerivatives.l1_reg_derivative(w_hat)\n","assert np.allclose(l1_reg_derivative, ref_dict['l1_reg_derivative'], atol=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rv26vjOvpVhQ"},"source":["### Test 5: MSE (0.05 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"5a986e8b66ceb8734057c78e8cabcfaa","grade":true,"grade_id":"cell-5d56bb4222ee1e7c","locked":true,"points":0.05,"schema_version":3,"solution":false,"task":false},"id":"IssRkzuapVhQ"},"source":["mse = LossAndDerivatives.mse(X_ref, y_ref, w_hat)\n","assert np.allclose(mse, ref_dict['mse'], atol=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RmXFTjOXpVhQ"},"source":["### Test 6: MAE (0.05 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"de373f459ca5fb9264bdb6e410bd7d0b","grade":true,"grade_id":"cell-8155e619427ac916","locked":true,"points":0.05,"schema_version":3,"solution":false,"task":false},"id":"RwrgyiPzpVhQ"},"source":["mae = LossAndDerivatives.mae(X_ref, y_ref, w_hat)\n","assert np.allclose(mae, ref_dict['mae'], atol=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1cA-90DvpVhR"},"source":["### Test 7: L2 reg (0.05 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"d0d2e9f6fa17691c83c2620821efa555","grade":true,"grade_id":"cell-c7ccfce79ecbadc3","locked":true,"points":0.05,"schema_version":3,"solution":false,"task":false},"id":"Nr4jhSM1pVhR"},"source":["l2_reg = LossAndDerivatives.l2_reg(w_hat)\n","assert np.allclose(l2_reg, ref_dict['l2_reg'], atol=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJarvCRPpVhR"},"source":["### Test 8: L1 reg (0.05 points)"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"8712dc1bb12b1dfd6605ab1e61e024c4","grade":true,"grade_id":"cell-1e1aa415f6d381f7","locked":true,"points":0.05,"schema_version":3,"solution":false,"task":false},"id":"-fXsAA8-pVhR"},"source":["l1_reg = LossAndDerivatives.l1_reg(w_hat)\n","assert np.allclose(l1_reg, ref_dict['l1_reg'], atol=1e-4)   "],"execution_count":null,"outputs":[]}]}